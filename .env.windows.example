# Configuración para ejecutar el asistente empaquetado en Windows
# Copia este archivo como ".env" y ajusta los valores según tu entorno.

# URL del servidor local expuesto por LM Studio
LM_STUDIO_BASE_URL=http://127.0.0.1:1234/v1

# Modelo cargado en LM Studio (debe coincidir con el nombre que aparece en la app)
LM_STUDIO_MODEL=Meta-Llama-3-8B-Instruct

# Parámetros para faster-whisper
WHISPER_MODEL_SIZE=small
WHISPER_COMPUTE_TYPE=auto
WHISPER_LANGUAGE=

# Carpeta relativa al ejecutable donde se guardarán las notas
NOTES_ROOT=notes

# Arranca automáticamente los servicios auxiliares al abrir el asistente
AUTO_BOOTSTRAP_SERVICES=true
AUTO_OPEN_OBSIDIAN=true

# Tiempo máximo (segundos) para que los servicios estén activos
BOOTSTRAP_TIMEOUT_SECONDS=120

# Recursos incluidos dentro de la carpeta portable
DOCKER_COMPOSE_FILE=docker-compose.yml
DOCKER_COMPOSE_COMMAND=docker compose

# Comando para iniciar LM Studio en modo servidor local
LM_STUDIO_START_COMMAND=bundled\\lm-studio\\lmstudio.exe --server --hostname 127.0.0.1 --port 1234 --model Meta-Llama-3-8B-Instruct
LM_STUDIO_WORKDIR=bundled\\lm-studio

# Ejecutable y vault portable de Obsidian
OBSIDIAN_VAULT=notes
OBSIDIAN_EXECUTABLE=bundled\\obsidian\\Obsidian.exe

# Tema visual del asistente
GUI_THEME=superhero
