# URL base del servidor OpenAI-compatible de LM Studio
LM_STUDIO_BASE_URL=http://host.docker.internal:1234/v1

# Modelo expuesto por LM Studio
LM_STUDIO_MODEL=Meta-Llama-3-8B-Instruct

# Tamaño del modelo de Whisper a utilizar (tiny, base, small, medium, large-v2)
WHISPER_MODEL_SIZE=small

# Tipo de cómputo para faster-whisper (auto, int8, float16, etc.)
WHISPER_COMPUTE_TYPE=auto

# Idioma forzado para la transcripción (por ejemplo "es" para español).
# Si se deja vacío se detectará automáticamente.
WHISPER_LANGUAGE=

# Carpeta donde se guardarán las notas en el contenedor (se mapea desde docker-compose)
NOTES_ROOT=/app/notes
